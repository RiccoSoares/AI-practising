{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training a cnn to recognize cats and dogs\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricco/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/home/ricco/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/ricco/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "#initializing the CNN\n",
    "classifier= Sequential()\n",
    "#Step 1- adding the Convolutional Layer\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape= (64,64,3), activation= 'relu'))\n",
    "#Step 2- adding MaxPooling Layer\n",
    "classifier.add(MaxPooling2D(pool_size= (2,2)))\n",
    "#Step 3- Flattening\n",
    "classifier.add(Flatten())\n",
    "#Step 4- Classic ANN with fully-connected layers\n",
    "classifier.add(Dense(output_dim= 128, activation= 'relu'))\n",
    "classifier.add(Dense(output_dim= 1, activation= 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the whole model\n",
    "classifier.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/3\n",
      "8000/8000 [==============================] - 1308s 164ms/step - loss: 0.3912 - accuracy: 0.8152 - val_loss: 0.5696 - val_accuracy: 0.7548\n",
      "Epoch 2/3\n",
      "8000/8000 [==============================] - 1282s 160ms/step - loss: 0.1506 - accuracy: 0.9413 - val_loss: 0.6341 - val_accuracy: 0.7491\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 1325s 166ms/step - loss: 0.0807 - accuracy: 0.9707 - val_loss: 1.6327 - val_accuracy: 0.7561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fa2e141d290>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the image pre-processing step\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 8000,\n",
    "                         epochs = 3,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricco/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  \"\"\"\n",
      "/home/ricco/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  del sys.path[0]\n",
      "/home/ricco/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
      "/home/ricco/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=512)`\n",
      "/home/ricco/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:38: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n"
     ]
    }
   ],
   "source": [
    "#time to improve!\n",
    "#building a CNN with more layers\n",
    "classifier= Sequential()\n",
    "\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape=(64, 64, 3), activation= 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size= (2,2)))\n",
    "\n",
    "classifier.add(Convolution2D(64, 3, 3, activation= 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size= (2,2)))\n",
    "\n",
    "classifier.add(Convolution2D(128, 3, 3, activation= 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size= (2,2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(output_dim= 512, activation= 'relu'))\n",
    "\n",
    "classifier.add(Dense(output_dim= 1, activation= 'sigmoid'))\n",
    "\n",
    "classifier.compile(optimizer= 'adam', loss= 'binary_crossentropy' ,metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/3\n",
      "8000/8000 [==============================] - 1579s 197ms/step - loss: 0.3123 - accuracy: 0.8548 - val_loss: 0.5507 - val_accuracy: 0.8255\n",
      "Epoch 2/3\n",
      "8000/8000 [==============================] - 1526s 191ms/step - loss: 0.0682 - accuracy: 0.9750 - val_loss: 0.2949 - val_accuracy: 0.8309\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 1604s 201ms/step - loss: 0.0373 - accuracy: 0.9871 - val_loss: 0.3964 - val_accuracy: 0.8345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fa2e0f1a510>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the image pre-processing step\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 8000,\n",
    "                         epochs = 3,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussing Results:\n",
    "\n",
    "    Adding more layers to the CNN resulted in substiancial improving results. Using three epochs caused overfitting (some ideas to reduce it will be discussed further). This can be seen in the last 2 epochs, where the accuracy improved signifficantly and val_accuracy changed to slightly better "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricco/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(128, 128,..., activation=\"relu\")`\n",
      "  \"\"\"\n",
      "/home/ricco/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  if __name__ == '__main__':\n",
      "/home/ricco/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
      "  del sys.path[0]\n",
      "/home/ricco/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=512)`\n",
      "/home/ricco/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n"
     ]
    }
   ],
   "source": [
    "#trying increasing the input size and using dropout\n",
    "from keras.layers import Dropout\n",
    "classifier= Sequential()\n",
    "#convolutional layer (we're doubling image dimensions)\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape=(128, 128, 3), activation= 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size= (2,2)))\n",
    "classifier.add(Dropout(0.25))\n",
    "\n",
    "classifier.add(Convolution2D(64, 3, 3, activation= 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size= (2,2)))\n",
    "classifier.add(Dropout(0.25))\n",
    "\n",
    "classifier.add(Convolution2D(128, 3, 3, activation= 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size= (2,2)))\n",
    "classifier.add(Dropout(0.25))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "#the ANN\n",
    "#hidden layer\n",
    "classifier.add(Dense(output_dim= 512, activation= 'relu'))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(output_dim= 1, activation= 'sigmoid'))\n",
    "#compiling\n",
    "classifier.compile(optimizer= 'adam', loss= 'binary_crossentropy' ,metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 4064s 508ms/step - loss: 0.4541 - accuracy: 0.7648 - val_loss: 0.2601 - val_accuracy: 0.8390\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 4004s 500ms/step - loss: 0.1884 - accuracy: 0.9238 - val_loss: 1.4385 - val_accuracy: 0.8459\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 3982s 498ms/step - loss: 0.1168 - accuracy: 0.9563 - val_loss: 0.8331 - val_accuracy: 0.8606\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 3979s 497ms/step - loss: 0.0894 - accuracy: 0.9674 - val_loss: 0.4142 - val_accuracy: 0.8794\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 3877s 485ms/step - loss: 0.0789 - accuracy: 0.9727 - val_loss: 1.1858 - val_accuracy: 0.8736\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 3882s 485ms/step - loss: 0.0700 - accuracy: 0.9762 - val_loss: 0.5823 - val_accuracy: 0.8629\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 3870s 484ms/step - loss: 0.0669 - accuracy: 0.9773 - val_loss: 1.3121 - val_accuracy: 0.8760\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 3881s 485ms/step - loss: 0.0642 - accuracy: 0.9783 - val_loss: 0.1545 - val_accuracy: 0.8714\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 3937s 492ms/step - loss: 0.0633 - accuracy: 0.9792 - val_loss: 0.1141 - val_accuracy: 0.8725\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 3914s 489ms/step - loss: 0.0618 - accuracy: 0.9802 - val_loss: 0.4041 - val_accuracy: 0.8867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fa2c1d83f10>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (128, 128),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (128, 128),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 8000,\n",
    "                         epochs = 10,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussing Results:\n",
    "\n",
    "    The idea here was to refine the neural network by enlarging the images and reduce the domminance between features with the dropout method. Several epochs were added since is plausible that a more refined learning requires more training\n",
    "    \n",
    "    A first observation to what happened in practise is that the starting accuracy was lower than in previous networks. The CNN took more time to learn and to be fitted, but the results were way better.\n",
    "    \n",
    "    Some ideas to get better results are to run more epochs, add more layers and decrease the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
